.. trust-ml documentation master file, created by
   sphinx-quickstart on Thu Jun  1 22:48:40 2023.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Trust-ML
========

Trust-ML is a machine learning-driven adversarial data generator that introduces naturally occurring distortions to the
original dataset to generate an adversarial subset. This framework provides a custom mix of distortions for evaluating
robustness of image classification models against both true negatives and false positives. Our framework enables users
to audit their algorithms with customizable distortions. With the help of :doc:`RLAB <rlab>`, we can generate more
effective and efficient adversarial samples than other distortion-based benchmarks.
In our experiments, we demonstrate that **samples generated with our framework cause greater accuracy degradation of
state-of-the-art adversarial robustness methods (as tracked by** `RobustBench <https://robustbench.github.io/>`_) **than
ImageNet-C and CIFAR-10-C**. Examples of images generated by our framework are shown below.


.. figure:: images/imagenet-examples-blur.png
   :scale: 70 %
   :alt: A subset of images from each of original ImageNet, ImageNet-C, and our distorted version of ImageNet
   :align: center

   A subset of images from each of original ImageNet, ImageNet-C, and our distorted version of ImageNet. The images
   shown are for severity level 5 of the Gaussian blur distortion. For the same severity level, images from ours retain
   much more clarity while being more challenging to classify.


.. figure:: images/imagenet-examples-noise.png
   :scale: 70 %
   :alt: A subset of images from each of original ImageNet, ImageNet-C, and our distorted version of ImageNet
   :align: center

   A subset of images from each of original ImageNet, ImageNet-C, and our distorted version of ImageNet. The images
   shown are for severity level 5 of the Gaussian noise distortion. For the same severity level, images from ours retain
   much more clarity while being more challenging to classify.

Features
--------

* Generate adversarial samples for any type of distortion (see examples in figures below)
* Generate samples at multiple distortion levels (severity/difficulty levels)
* Supports a customizable mix of distortions during generation (see the lower figure below)
* Robustness can be audited for both true negatives and false positives
* As RLAB only requires black-box access, any model (or ensemble) can be used as the victim in the generator


.. figure:: images/distortion-types.png
   :scale: 70 %
   :alt: Some examples of distortions that are supported by Trust-ML
   :align: center

   Some examples of distortions that are supported by Trust-ML


.. figure:: images/mixed-distortions.png
   :scale: 70 %
   :alt: Trust-ML supports a customizable mix of distortions in the generator
   :align: center

   Trust-ML supports a customizable mix of distortions in the generator



Getting Started
---------------

1. Head to the :doc:`installation` page to get set up with our software
2. Head to the :doc:`usage` page to get familiar with generating your own distorted data
3. You can evaluate on our distorted versions of ImageNet and CIFAR-10 used in the paper from `Zenodo <https://zenodo.org/record/8034833>`_ (see :doc:`usage` for dataset structure)


Links
-----

* We host the source code for our benchmark on `GitHub <https://github.com/HewlettPackard/trust-ml/>`_.
* We provide our distorted versions of the ImageNet and CIFAR-10 datasets for download on `Zenodo <https://zenodo.org/record/8034833>`_.

.. toctree::
   :hidden:

   Home <self>
   rlab
   installation
   usage
